{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-embeddings.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+ExRKbgu8HWNpKjcLr1Vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apresland/tensorflow-nlp/blob/word-embeddings/word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZr7vIv-qRR_"
      },
      "source": [
        "# Word Embeddings\n",
        "This notebook denonstrates creating word embeddings in tensorflow. We will train a word embeddings using a simple Keras model for a sentiment classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI0VdVXvpNcR"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDz_2RJsq_lE"
      },
      "source": [
        "# Download the IMDBÂ dataset\n",
        "The IMDB dataset is available as a  TensorFlow datasets. The following code downloads the IMDB dataset: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl-tKTysq_4k"
      },
      "source": [
        "# Split the training set 80%:20%\n",
        "train_ds, val_ds, test_ds = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:80%]', 'train[80%:]', 'test'),\n",
        "    batch_size=1024,\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wwQWsSy8x_j"
      },
      "source": [
        "# Inspect some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLf2olKJ8yOM"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PhTurAubAD"
      },
      "source": [
        "# Text pre-processing\n",
        "Define the dataset preprocessing steps required for the classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2bd7UETubjP"
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "\n",
        "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "# Normalize, split, and map strings to integers.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHPot2wi3K8N"
      },
      "source": [
        "# Create a classifiction model\n",
        "Use Keras to define the sentiment classification model in a \"continuous bag of words\" style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FhSARe23Lan"
      },
      "source": [
        "EMBEDDING_DIM=16\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  vectorize_layer,\n",
        "  tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, name=\"embedding\"),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvf7R-HL5h7g"
      },
      "source": [
        "# Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWum5Yj25ic8"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A4FgaTp5zIO"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVZ4RoVr5xtV"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds, \n",
        "    epochs=15,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ0AGlFe-iga"
      },
      "source": [
        "Visualize the metrics in TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGVzBK3i-YGG"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}